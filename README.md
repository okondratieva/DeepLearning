# DeepLearning

## Описание файлов
* ```reduce_dataset.py``` - скрипт для вычленения из оригинального набора данных наиболее репрезентативных категорий
* ```resize_dataset.py``` - скрипт для изменения размерности данных
* ```prepare_dataset.py``` - скрипт для подготовки данных под *mxnet*
* ```load_dataset.py``` - функции для загрузки данных в скрипт обучения
* ```blocks.py``` - основные конструкционные блоки сетей
* ```fit.py``` - универсальный скрипт обучения, формирующий все необходимые отчёты
* ```parse_log.py``` - скрипт, формирующий сводную таблицу из журнала обучения

## Результаты

|№ лабораторной работы|Размерность данных|Конфигурация сети|Параметры обучения|Точность на тестовом множестве (%)|
|--|--|--|--|--|
|2|3х210x140|<li>Полносвязная сеть<li> Активационная функция: ReLu<li> Размер слоев: 8820, 4410, 2200, 1100, 550, 270, 135, 68, 34<li> Выходной слой: softmax + cross-entropy|<li>Оптимизатор: SGD<li> Скорость обучения 0.0001<li> Количество эпох: 60<li> Размер batch: 10   |22,29|
|3|3x432x288|<li>Сверточная сеть<li> Активационная функция: ReLu <li> Конфигурация слоев: <ol><li> 3 сверточных слоя с 2-кратным pooling <li> слой inception v1 (на выходе 160 карт признаков)<li> слой inception v1 (выход - 320 карт признаков)<li> сверточный слой (128 карт признаков)<li> классификатор полносвязный с 3 слоями и drop-out (вер-ть 0.5) после каждого слоя</ol>|<li>Оптимизатор: SGD<li> Скорость обучения 0.0001<li> Количество эпох: 120<li>Размер batch: 10 |42.72|
|4|3x108x72|<li>Полносвязная сеть<li> Активационная функция: ReLu<li> Размер слоев: 2300, 1150, 575, 288, 144, 72, 36<li> Выходной слой: softmax + cross-entropy|<li>Оптимизатор: SGD<li> Скорость обучения 0.0001<li> Количество эпох: 60<li> Размер batch: 10<li> Инициализация весов: автокодировщик|11.63|
|5|3x224x224|<li>SquizeeNet v1.1|<li>Оптимизатор: SGD<li> Скорость обучения 0.004<li> Количество эпох: 120<li>Размер batch: 10<li> Инициализация весов: предобучение на ImageNet dataset |58.1|
